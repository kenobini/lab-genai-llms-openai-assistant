{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an assistant to answer a topic of your choosing:\n",
    " - Upload a file of your interest\n",
    " - Add Instructions to the prompt\n",
    " - Use the assistant in Playground mode\n",
    "\n",
    " https://platform.openai.com/playground/assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "#OpenAI API key\n",
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the assistant\n",
    "from openai import OpenAI\n",
    " \n",
    "client = OpenAI(api_key=api_key)\n",
    " \n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Pickleball Coaching Assistant\",\n",
    "  instructions=\"You are an expert in pickleball coaching and certification. Answer questions using the uploaded PPR Study Guide.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector store called \"Datavisualization Documents\"\n",
    "vector_store = client.beta.vector_stores.create(name=\"pickl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"/Users/paolarivera/Documents/Ironhack/Week 8/Day 2/lab-genai-llms-openai-assistant-main/your-code/PPR_StudyGuide_V10.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk to your assistant via the API\n",
    "\n",
    "https://platform.openai.com/docs/assistants/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m run \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mcreate_and_poll(\n\u001b[1;32m     12\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid, assistant_id\u001b[38;5;241m=\u001b[39massistant\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mlist(thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid, run_id\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mid))\n\u001b[0;32m---> 17\u001b[0m message_content \u001b[38;5;241m=\u001b[39m messages[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(message_content\u001b[38;5;241m.\u001b[39mvalue)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What are the key skills required to become a certified pickleball coach?\",\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "print(message_content.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant ID: asst_Btf2j4ThkYWJA4b75xTf5ibw\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")  # Replace with your actual API key\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Pickleball Coaching Assistant\",\n",
    "    instructions=\"You are an expert in pickleball coaching and certification. Answer questions using the uploaded PPR Study Guide.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}]  # Enables document-based responses\n",
    ")\n",
    "\n",
    "print(f\"Assistant ID: {assistant.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread ID: thread_6ty7U9JnAR5qPcMDPWeaxPr0\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "print(f\"Thread ID: {thread.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID: msg_6t9AQOD90S9bjvGxCNTZeV9A\n"
     ]
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What are the key skills required to become a certified pickleball coach?\"\n",
    ")\n",
    "\n",
    "print(f\"Message ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: run_sp8XQ3RMr0VYoowswciWOQ9x\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "print(f\"Run ID: {run.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: It seems that there hasn't been a study guide uploaded yet. Could you please upload the PPR Study Guide? This will help me to provide you with accurate information specific to the pickleball certification process.\n",
      "\n",
      "user: What are the key skills required to become a certified pickleball coach?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Wait a few seconds for completion\n",
    "time.sleep(5)\n",
    "\n",
    "# Fetch response\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "for msg in messages.data:\n",
    "    print(f\"{msg.role}: {msg.content[0].text.value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Missing required parameter: 'attachments[0].tools'.\", 'type': 'invalid_request_error', 'param': 'attachments[0].tools', 'code': 'missing_required_parameter'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m file \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     11\u001b[0m     file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/paolarivera/Documents/Ironhack/Week 8/Day 2/lab-genai-llms-openai-assistant-main/your-code/PPR_StudyGuide_V10.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     12\u001b[0m     purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Send a message referencing the file\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m message \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     17\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     18\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the key skills required to become a certified pickleball coach?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     attachments\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: file\u001b[38;5;241m.\u001b[39mid}]\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Run the assistant\u001b[39;00m\n\u001b[1;32m     24\u001b[0m run \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mcreate_and_poll(\n\u001b[1;32m     25\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     26\u001b[0m     assistant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour-assistant-id\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your actual Assistant ID\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/resources/beta/threads/messages.py:102\u001b[0m, in \u001b[0;36mMessages.create\u001b[0;34m(self, thread_id, content, role, attachments, metadata, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `thread_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/threads/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/messages\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    104\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    105\u001b[0m         {\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content,\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: role,\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattachments\u001b[39m\u001b[38;5;124m\"\u001b[39m: attachments,\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    110\u001b[0m         },\n\u001b[1;32m    111\u001b[0m         message_create_params\u001b[38;5;241m.\u001b[39mMessageCreateParams,\n\u001b[1;32m    112\u001b[0m     ),\n\u001b[1;32m    113\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    114\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    115\u001b[0m     ),\n\u001b[1;32m    116\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mMessage,\n\u001b[1;32m    117\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    961\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    962\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    963\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    964\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    965\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    966\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Missing required parameter: 'attachments[0].tools'.\", 'type': 'invalid_request_error', 'param': 'attachments[0].tools', 'code': 'missing_required_parameter'}}"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")  # Replace with your API key\n",
    "\n",
    "# Create a thread (conversation session)\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Upload and attach the file\n",
    "file = client.files.create(\n",
    "    file=open(\"/Users/paolarivera/Documents/Ironhack/Week 8/Day 2/lab-genai-llms-openai-assistant-main/your-code/PPR_StudyGuide_V10.pdf\", \"rb\"),\n",
    "    purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Send a message referencing the file\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What are the key skills required to become a certified pickleball coach?\",\n",
    "    attachments=[{\"file_id\": file.id}]\n",
    ")\n",
    "\n",
    "# Run the assistant\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=\"your-assistant-id\"  # Replace with your actual Assistant ID\n",
    ")\n",
    "\n",
    "# Wait for processing\n",
    "time.sleep(5)\n",
    "\n",
    "# Retrieve messages from the thread\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id).data\n",
    "\n",
    "# Check if we received a response\n",
    "if messages:\n",
    "    message_content = messages[-1].content[0].text.value  # Get latest message\n",
    "    print(message_content)\n",
    "else:\n",
    "    print(\"No response received from the assistant.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully! File ID: file-8VD4p9LxzNkdbfiWUavrtB\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")  # Replace with your actual API key\n",
    "\n",
    "# Upload the file for assistant use\n",
    "file = client.files.create(\n",
    "    file=open('/Users/paolarivera/Documents/Ironhack/Week 8/Day 2/lab-genai-llms-openai-assistant-main/your-code/PPR_StudyGuide_V10.pdf', \"rb\"),  \n",
    "    purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "print(f\"File uploaded successfully! File ID: {file.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant Created! ID: asst_Xp9Lc5xY7BYy8IAaJg0SsBox\n"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Pickleball Coaching Assistant\",\n",
    "    instructions=(\n",
    "        \"You are an expert in pickleball coaching and certification. \"\n",
    "        \"You must use the uploaded PPR Study Guide to provide accurate answers. \"\n",
    "        \"When responding, summarize relevant information from the document instead of general knowledge. \"\n",
    "        \"If the question is unrelated to the document, say 'I can only answer questions related to the PPR Study Guide.'\"\n",
    "    ),\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}]  # ✅ Ensures the assistant can search the document\n",
    ")\n",
    "\n",
    "print(f\"Assistant Created! ID: {assistant.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent! Message ID: msg_J9ciWrabfPyu4oDTrr8pzWJD\n"
     ]
    }
   ],
   "source": [
    "# Create a conversation thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# ✅ FIXED: Attach file correctly (tools must be an object, not a string)\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Based on the PPR Study Guide, what are the key skills required to become a certified pickleball coach? \"\n",
    "            \"Please provide a detailed response using the document.\",\n",
    "    attachments=[{\"file_id\": file.id, \"tools\": [{\"type\": \"file_search\"}]}]  # ✅ Ensures file is referenced\n",
    ")\n",
    "\n",
    "print(f\"Message sent! Message ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant Response:\n",
      " Based on the PPR Study Guide, what are the key skills required to become a certified pickleball coach? Please provide a detailed response using the document.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Run the assistant\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# Wait a few seconds for processing\n",
    "time.sleep(5)\n",
    "\n",
    "# Retrieve the assistant's response\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id).data\n",
    "\n",
    "if messages:\n",
    "    message_content = messages[-1].content[0].text.value  # Get latest response\n",
    "    print(\"Assistant Response:\\n\", message_content)\n",
    "else:\n",
    "    print(\"No response received from the assistant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Logs:\n",
      " [Run(id='run_cO7Ue0Z8zmGysFiHhkZPqQvc', assistant_id='asst_Xp9Lc5xY7BYy8IAaJg0SsBox', cancelled_at=None, completed_at=None, created_at=1739165339, expires_at=None, failed_at=1739165348, incomplete_details=None, instructions=\"You are an expert in pickleball coaching and certification. You must use the uploaded PPR Study Guide to provide accurate answers. When responding, summarize relevant information from the document instead of general knowledge. If the question is unrelated to the document, say 'I can only answer questions related to the PPR Study Guide.'\", last_error=LastError(code='rate_limit_exceeded', message='Request too large for gpt-4o in organization org-qtRC3ZOVzMgSGpdWDFg3iWoG on tokens per min (TPM): Limit 30000, Requested 32956. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.'), max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1739165340, status='failed', thread_id='thread_NtzyS8diEplaTQGAOg7COh1x', tool_choice='auto', tools=[FileSearchTool(type='file_search', file_search=FileSearch(max_num_results=None, ranking_options=FileSearchRankingOptions(score_threshold=0.0, ranker='default_2024_08_21')))], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=25, prompt_tokens=911, total_tokens=936, prompt_token_details={'cached_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0}), temperature=1.0, top_p=1.0, tool_resources={}, reasoning_effort=None)]\n"
     ]
    }
   ],
   "source": [
    "retrieval_logs = client.beta.threads.runs.list(thread_id=thread.id).data\n",
    "print(\"Retrieval Logs:\\n\", retrieval_logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 31 chunks.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, max_chars=4000):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_chunks = []\n",
    "    chunk = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        page_text = page.get_text(\"text\") + \"\\n\"\n",
    "        if len(chunk) + len(page_text) < max_chars:\n",
    "            chunk += page_text\n",
    "        else:\n",
    "            text_chunks.append(chunk)\n",
    "            chunk = page_text\n",
    "\n",
    "    if chunk:\n",
    "        text_chunks.append(chunk)\n",
    "\n",
    "    return text_chunks\n",
    "\n",
    "pdf_path = '/Users/paolarivera/Documents/Ironhack/Week 8/Day 2/lab-genai-llms-openai-assistant-main/your-code/PPR_StudyGuide_V10.pdf'\n",
    "ppr_text_chunks = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(f\"Extracted {len(ppr_text_chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Relevant Sections:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "def find_relevant_chunks(query, text_chunks):\n",
    "    relevant_chunks = [chunk for chunk in text_chunks if query.lower() in chunk.lower()]\n",
    "    return relevant_chunks[:3]  # Limit to 3 most relevant chunks\n",
    "\n",
    "query = \"key skills required to become a certified pickleball coach\"\n",
    "relevant_text = find_relevant_chunks(query, ppr_text_chunks)\n",
    "\n",
    "print(\"Most Relevant Sections:\\n\", relevant_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-api-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour-api-key\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with your actual API key\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m assistant \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickleball Coaching Assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     instructions\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert in pickleball coaching and certification. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse the provided excerpts from the PPR Study Guide to answer questions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize and provide only information found in the excerpts.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     ),\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m thread \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Send only the relevant chunks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/resources/beta/assistants.py:149\u001b[0m, in \u001b[0;36mAssistants.create\u001b[0;34m(self, model, description, instructions, metadata, name, response_format, temperature, tool_resources, tools, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mCreate an assistant with a model and instructions.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/assistants\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    152\u001b[0m         {\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: description,\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: instructions,\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_resources,\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    163\u001b[0m         },\n\u001b[1;32m    164\u001b[0m         assistant_create_params\u001b[38;5;241m.\u001b[39mAssistantCreateParams,\n\u001b[1;32m    165\u001b[0m     ),\n\u001b[1;32m    166\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    167\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    168\u001b[0m     ),\n\u001b[1;32m    169\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mAssistant,\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    961\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    962\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    963\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    964\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    965\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    966\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-api-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"your-api-key\")  # Replace with your actual API key\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Pickleball Coaching Assistant\",\n",
    "    instructions=(\n",
    "        \"You are an expert in pickleball coaching and certification. \"\n",
    "        \"Use the provided excerpts from the PPR Study Guide to answer questions. \"\n",
    "        \"Summarize and provide only information found in the excerpts.\"\n",
    "    ),\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Send only the relevant chunks\n",
    "message_content = f\"Based on the following text from the PPR Study Guide, answer the question:\\n\\n{relevant_text}\\n\\nQuestion: What are the key skills required to become a certified pickleball coach?\"\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=message_content\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id).data\n",
    "\n",
    "if messages:\n",
    "    print(\"Assistant Response:\\n\", messages[-1].content[0].text.value)\n",
    "else:\n",
    "    print(\"No response received from the assistant.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an assistant that will call a weather API, given the user's answer and return the proper answer.\n",
    "\n",
    "See the documentation of the weather API here: https://open-meteo.com/en/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': 52.52, 'longitude': 13.419998, 'generationtime_ms': 0.032782554626464844, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 38.0, 'hourly_units': {'time': 'iso8601', 'temperature_2m': '°C'}, 'hourly': {'time': ['2025-02-10T00:00', '2025-02-10T01:00', '2025-02-10T02:00', '2025-02-10T03:00', '2025-02-10T04:00', '2025-02-10T05:00', '2025-02-10T06:00', '2025-02-10T07:00', '2025-02-10T08:00', '2025-02-10T09:00', '2025-02-10T10:00', '2025-02-10T11:00', '2025-02-10T12:00', '2025-02-10T13:00', '2025-02-10T14:00', '2025-02-10T15:00', '2025-02-10T16:00', '2025-02-10T17:00', '2025-02-10T18:00', '2025-02-10T19:00', '2025-02-10T20:00', '2025-02-10T21:00', '2025-02-10T22:00', '2025-02-10T23:00', '2025-02-11T00:00', '2025-02-11T01:00', '2025-02-11T02:00', '2025-02-11T03:00', '2025-02-11T04:00', '2025-02-11T05:00', '2025-02-11T06:00', '2025-02-11T07:00', '2025-02-11T08:00', '2025-02-11T09:00', '2025-02-11T10:00', '2025-02-11T11:00', '2025-02-11T12:00', '2025-02-11T13:00', '2025-02-11T14:00', '2025-02-11T15:00', '2025-02-11T16:00', '2025-02-11T17:00', '2025-02-11T18:00', '2025-02-11T19:00', '2025-02-11T20:00', '2025-02-11T21:00', '2025-02-11T22:00', '2025-02-11T23:00', '2025-02-12T00:00', '2025-02-12T01:00', '2025-02-12T02:00', '2025-02-12T03:00', '2025-02-12T04:00', '2025-02-12T05:00', '2025-02-12T06:00', '2025-02-12T07:00', '2025-02-12T08:00', '2025-02-12T09:00', '2025-02-12T10:00', '2025-02-12T11:00', '2025-02-12T12:00', '2025-02-12T13:00', '2025-02-12T14:00', '2025-02-12T15:00', '2025-02-12T16:00', '2025-02-12T17:00', '2025-02-12T18:00', '2025-02-12T19:00', '2025-02-12T20:00', '2025-02-12T21:00', '2025-02-12T22:00', '2025-02-12T23:00', '2025-02-13T00:00', '2025-02-13T01:00', '2025-02-13T02:00', '2025-02-13T03:00', '2025-02-13T04:00', '2025-02-13T05:00', '2025-02-13T06:00', '2025-02-13T07:00', '2025-02-13T08:00', '2025-02-13T09:00', '2025-02-13T10:00', '2025-02-13T11:00', '2025-02-13T12:00', '2025-02-13T13:00', '2025-02-13T14:00', '2025-02-13T15:00', '2025-02-13T16:00', '2025-02-13T17:00', '2025-02-13T18:00', '2025-02-13T19:00', '2025-02-13T20:00', '2025-02-13T21:00', '2025-02-13T22:00', '2025-02-13T23:00', '2025-02-14T00:00', '2025-02-14T01:00', '2025-02-14T02:00', '2025-02-14T03:00', '2025-02-14T04:00', '2025-02-14T05:00', '2025-02-14T06:00', '2025-02-14T07:00', '2025-02-14T08:00', '2025-02-14T09:00', '2025-02-14T10:00', '2025-02-14T11:00', '2025-02-14T12:00', '2025-02-14T13:00', '2025-02-14T14:00', '2025-02-14T15:00', '2025-02-14T16:00', '2025-02-14T17:00', '2025-02-14T18:00', '2025-02-14T19:00', '2025-02-14T20:00', '2025-02-14T21:00', '2025-02-14T22:00', '2025-02-14T23:00', '2025-02-15T00:00', '2025-02-15T01:00', '2025-02-15T02:00', '2025-02-15T03:00', '2025-02-15T04:00', '2025-02-15T05:00', '2025-02-15T06:00', '2025-02-15T07:00', '2025-02-15T08:00', '2025-02-15T09:00', '2025-02-15T10:00', '2025-02-15T11:00', '2025-02-15T12:00', '2025-02-15T13:00', '2025-02-15T14:00', '2025-02-15T15:00', '2025-02-15T16:00', '2025-02-15T17:00', '2025-02-15T18:00', '2025-02-15T19:00', '2025-02-15T20:00', '2025-02-15T21:00', '2025-02-15T22:00', '2025-02-15T23:00', '2025-02-16T00:00', '2025-02-16T01:00', '2025-02-16T02:00', '2025-02-16T03:00', '2025-02-16T04:00', '2025-02-16T05:00', '2025-02-16T06:00', '2025-02-16T07:00', '2025-02-16T08:00', '2025-02-16T09:00', '2025-02-16T10:00', '2025-02-16T11:00', '2025-02-16T12:00', '2025-02-16T13:00', '2025-02-16T14:00', '2025-02-16T15:00', '2025-02-16T16:00', '2025-02-16T17:00', '2025-02-16T18:00', '2025-02-16T19:00', '2025-02-16T20:00', '2025-02-16T21:00', '2025-02-16T22:00', '2025-02-16T23:00'], 'temperature_2m': [-0.3, -0.5, -0.6, -0.6, -0.6, -0.7, -0.8, -0.9, -0.9, -0.4, 0.5, 1.4, 2.5, 3.4, 3.7, 3.6, 2.9, 2.0, 1.3, 0.6, 0.1, -0.3, -0.7, -1.2, -1.5, -1.9, -2.3, -2.6, -2.8, -3.1, -3.3, -3.4, -3.1, -2.3, -1.0, 0.1, 1.2, 2.0, 2.3, 2.1, 1.5, 0.9, 0.3, -0.2, -0.6, -0.9, -1.2, -1.7, -2.0, -2.3, -2.5, -2.8, -3.5, -3.6, -3.7, -3.6, -3.0, -2.0, -0.6, 0.9, 2.1, 2.7, 2.9, 2.4, 1.8, 1.4, 1.1, 0.9, 0.8, 0.7, 0.6, 0.3, -0.3, -0.4, -0.3, -0.2, -0.1, -0.1, -0.0, 0.1, 0.2, 0.5, 1.2, 2.0, 2.7, 3.2, 3.6, 3.7, 3.4, 2.8, 2.4, 2.1, 2.0, 1.8, 1.7, 1.6, 1.5, 1.4, 1.3, 1.1, 0.9, 0.7, 0.6, 0.7, 0.8, 0.9, 1.1, 1.2, 1.4, 1.6, 1.9, 1.9, 1.7, 1.2, 0.8, 0.6, 0.4, 0.2, -0.0, -0.2, -0.3, -0.5, -0.7, -0.9, -1.1, -1.4, -1.6, -1.7, -1.8, -1.8, -1.5, -1.0, -0.6, -0.3, -0.1, 0.0, -0.2, -0.6, -1.0, -1.3, -1.5, -1.8, -2.2, -2.6, -2.9, -3.1, -3.2, -3.3, -3.5, -3.7, -3.7, -3.6, -3.4, -3.0, -2.3, -1.4, -0.8, -0.6, -0.7, -0.9, -1.3, -1.9, -2.5, -3.1, -3.7, -4.2, -4.4, -4.6]}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather_forecast(latitude, longitude):\n",
    "    base_url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\": \"temperature_2m\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Example usage:\n",
    "forecast = get_weather_forecast(52.52, 13.41)\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to, there is a hint here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Chatbots / Assistants have a way to respond in json format. \n",
    "\n",
    "Explore the function calling functionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
